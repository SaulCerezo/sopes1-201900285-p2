# üê≥ Despliegue Kubernetes - Proyecto TweetsClima

Este proyecto se compone de varios microservicios escritos en Rust y Go, comunic√°ndose a trav√©s de gRPC y RabbitMQ. A continuaci√≥n se documentan los despliegues (Deployment), servicios (Service) e ingreso (Ingress) usados para desplegar la soluci√≥n en un cl√∫ster de Kubernetes.

### Estructura de Archivos YAML

Todos los archivos .yaml se encuentran en la carpeta k8s/ y cumplen con los siguientes prop√≥sitos:

|Archivo |Descripci√≥n |
| ------------- | ------------- | 
|rust-api-deployment.yaml| Despliega 2 r√©plicas del servicio REST en Rust|
|rust-api-service.yaml|Expone internamente el servicio Rust en el puerto 8000|
|go-entry-deployment.yaml| Despliega 2 r√©plicas del servidor gRPC en Go|
|go-entry-service.yaml|Expone internamente el servicio gRPC en el puerto 50051|
|analyzer-deployment.yaml|Despliega 1 r√©plica del consumidor de mensajes RabbitMQ|
|analyzer-service.yaml|(Opcional) Servicio para exponer el analyzer|
|rabbitmq-deployment.yaml|Despliega RabbitMQ con UI de administraci√≥n|
|rabbitmq-service.yaml|Expone internamente RabbitMQ (5672) y su UI (15672)|
|ingress.yaml|Expone el servicio REST (Rust) mediante Ingress|

### Comandos de Despliegue
Hay que asegurarse de estar autenticado con tu cl√∫ster de Kubernetes y tener configurado el contexto.

1. Aplicar todos los archivos:

```
kubectl apply -f k8s/

```
2. Verificar los pods:
```
kubectl get pods

```
3. Verificar los servicios:
```
kubectl get svc

```
4. Verificar el ingreso (Ingress):
```
kubectl get ingress

```

### Acceso V√≠a Ingress
Si tienes un Ingress Controller (como NGINX) y tu dominio apunta correctamente al cl√∫ster, podr√°s acceder al servicio REST as√≠:

```
http://<tu-dominio>/api

```
Por ejemplo:
```
http://34.122.55.100.nip.io/api

```

##  Ejemplo de Flujo
1. rust-api recibe peticiones HTTP en /api.
2. Se comunica con go-entry usando gRPC.
3. go-entry publica mensajes en RabbitMQ.
4. analyzer consume esos mensajes desde RabbitMQ y los almacena en un archivo .json.


## Rust-api creando la imagen

Hicimos un endpoint POST /input que:

* Recibe un array JSON con tweets del clima.

* Guarda los datos en memoria con Mutex Vec WeatherTweet.

* Responde con el n√∫mero de tweets recibidos y el total acumulado.

Se edito en main.rs para que escuche desde 0.0.0.0
```
    .bind(("0.0.0.0", 8000))?

```
Esto permite que el contenedor acepte conexiones desde fuera, como desde Postman o curl.

### Comandos que usamos para rust-api
```
    docker build -t rust-api:local .
    docker run --rm -p 8000:8000 rust-api:local
```
## Servidro de Go
creamos un sevidor y un cliente de forma local para ver si los tweets estan llegando 

```
    go run main.go
```

## Locust
Herramienta para pruebas de carga que te permite simular muchos usuarios haciendo peticiones a tu API
```
    locust --host http://localhost:8000 
```

Docker compose
Creamos un docker compose para ejecutar los servicos y exponerlos a la misma red

```
    docker compose up
    docker compose down
```
```
    docker compose restart analyzer
```
## Subiendo las imagenes a dockerhub
Etiqueta correctamente tus im√°genes con el nombre correcto:

```
    docker tag tweetsclima-rust-api saulcerezo/sopes1p2:rust-api-v1
    docker tag tweetsclima-go-entry saulcerezo/sopes1p2:go-entry-v1
    docker tag tweetsclima-analyzer saulcerezo/sopes1p2:analyzer-v1

```
hacemos push de cada una

```
    docker push saulcerezo/sopes1p2:rust-api-v1
    docker push saulcerezo/sopes1p2:go-entry-v1
    docker push saulcerezo/sopes1p2:analyzer-v1

```
-----------------------------------------

# DOCUMENTACION

### ¬øC√≥mo funciona Kafka?
Apache Kafka es una plataforma de mensajer√≠a distribuida que permite transmitir, almacenar y procesar flujos de datos en tiempo real. Se basa en un modelo publish-subscribe, donde:

* Productores publican mensajes en un t√≥pico.
* Consumidores se suscriben a ese t√≥pico y reciben mensajes.
* Kafka almacena mensajes de forma persistente y permite a m√∫ltiples consumidores leer a su ritmo.
* Est√° dise√±ado para ser escalable, tolerante a fallos y de alto rendimiento.

```
    ‚ö†Ô∏è Para este proyecto no utilice kafka pero si 
    hice uso de RabbitMQ que cumplen funciones similares (mensajeria)
```

### ¬øC√≥mo difiere Valkey de Redis?
Valkey es un fork (derivado) de Redis, creado despu√©s de que Redis Labs cambi√≥ su licencia a una menos permisiva.


| Caracter√≠stica | Redis | Valkey |
| ------------- | ------------- | ------------- |
| Licencia | Redis Source Available MIT (libre y abierta) (RSAL) | nuevo |
|Comunidad|Mantenido por Redis Inc.| Mantenido por la comunidad open source|
|Filosof√≠a|M√°s control comercial|Enfocado en la comunidad y libertad
|

```
    ‚ö†Ô∏è Para este proyecto no se utlizo ni valkey ni Redis
```
### ¬øEs mejor gRPC que HTTP?
Depende del caso de uso.

gRPC es un protocolo de comunicaci√≥n basado en HTTP/2 que utiliza Protocol Buffers. Es ideal para:

* Servicios internos entre microservicios.
* Comunicaci√≥n r√°pida y eficiente en entornos de alto rendimiento.
* Necesidad de tipado fuerte y streaming bidireccional.

Ventajas de gRPC sobre HTTP REST:
* Mejor rendimiento (m√°s ligero que JSON).
* Soporte de streaming.
* Contratos bien definidos mediante .proto.

```
En este proyecto use gRPC entre microservicios 
(Rust ‚Üí Go), lo cual es adecuado y m√°s eficiente 
que usar REST en ese tipo de comunicaci√≥n.
```

### ¬øHubo una mejora al utilizar dos r√©plicas en los deployments de API REST y gRPC? Justifique su respuesta.

S√≠, hay mejora, sobre todo en disponibilidad y balance de carga.

* M√°s r√©plicas = mayor capacidad de atender m√∫ltiples solicitudes simult√°neas.
* Tolerancia a fallos: si una instancia falla, otra sigue atendiendo.
* Mejor rendimiento bajo carga alta (como la generada con Locust).

```
usar 2 r√©plicas en un cl√∫ster de GCP o Kubernetes 
mejora escalabilidad y disponibilidad del sistema.
```

### Para los consumidores, ¬øQu√© utiliz√≥ y por qu√©?
Se us√≥ RabbitMQ como sistema de mensajer√≠a y un servicio Go llamado analyzer como consumidor:

* analyzer se suscribe a la cola de RabbitMQ y procesa los mensajes recibidos.
* Se eligi√≥ Go por su eficiencia en concurrencia y su buen soporte para integrarse con RabbitMQ.

```
Se eligio RabbitMQ por su simplicidad, soporte en 
Docker, y facilidad de uso en entornos de 
desarrollo.
```
